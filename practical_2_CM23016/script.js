let model;
let isDrawing = false;
let canvas, ctx;

// Initialize canvas
function initCanvas() {
  canvas = document.getElementById("drawCanvas");
  ctx = canvas.getContext("2d");
  ctx.fillStyle = "white";
  ctx.fillRect(0, 0, canvas.width, canvas.height);
  ctx.strokeStyle = "black";
  ctx.lineWidth = 20;
  ctx.lineCap = "round";
  ctx.lineJoin = "round";

  // Mouse events
  canvas.addEventListener("mousedown", startDrawing);
  canvas.addEventListener("mousemove", draw);
  canvas.addEventListener("mouseup", stopDrawing);
  canvas.addEventListener("mouseout", stopDrawing);

  // Touch events
  canvas.addEventListener("touchstart", handleTouch);
  canvas.addEventListener("touchmove", handleTouch);
  canvas.addEventListener("touchend", stopDrawing);
}

function startDrawing(e) {
  isDrawing = true;
  const rect = canvas.getBoundingClientRect();
  ctx.beginPath();
  ctx.moveTo(e.clientX - rect.left, e.clientY - rect.top);
}

function draw(e) {
  if (!isDrawing) return;
  const rect = canvas.getBoundingClientRect();
  ctx.lineTo(e.clientX - rect.left, e.clientY - rect.top);
  ctx.stroke();
}

function stopDrawing() {
  isDrawing = false;
}

function handleTouch(e) {
  e.preventDefault();
  const touch = e.touches[0];
  const mouseEvent = new MouseEvent(
    e.type === "touchstart" ? "mousedown" : "mousemove",
    {
      clientX: touch.clientX,
      clientY: touch.clientY,
    },
  );
  canvas.dispatchEvent(mouseEvent);
}

function clearCanvas() {
  ctx.fillStyle = "white";
  ctx.fillRect(0, 0, canvas.width, canvas.height);
  document.getElementById("predictionResult").style.display = "none";
}

// Create CNN model
function createModel() {
  const model = tf.sequential();

  // First convolutional layer
  model.add(
    tf.layers.conv2d({
      inputShape: [28, 28, 1],
      filters: 32,
      kernelSize: 3,
      activation: "relu",
      padding: "same",
    }),
  );
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

  // Second convolutional layer
  model.add(
    tf.layers.conv2d({
      filters: 64,
      kernelSize: 3,
      activation: "relu",
      padding: "same",
    }),
  );
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

  // Third convolutional layer
  model.add(
    tf.layers.conv2d({
      filters: 64,
      kernelSize: 3,
      activation: "relu",
      padding: "same",
    }),
  );

  // Flatten and dense layers
  model.add(tf.layers.flatten());
  model.add(tf.layers.dropout({ rate: 0.5 }));
  model.add(tf.layers.dense({ units: 128, activation: "relu" }));
  model.add(tf.layers.dropout({ rate: 0.5 }));
  model.add(tf.layers.dense({ units: 10, activation: "softmax" }));

  return model;
}

// MNIST Data class
class MnistData {
  constructor() {
    this.shuffledTrainIndex = 0;
    this.shuffledTestIndex = 0;
  }

  async load() {
    // Using the working CDN links
    const MNIST_IMAGES_SPRITE_PATH =
      "https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png";
    const MNIST_LABELS_PATH =
      "https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8";

    const img = new Image();
    const canvas = document.createElement("canvas");
    const ctx = canvas.getContext("2d");

    const imgRequest = new Promise((resolve, reject) => {
      img.crossOrigin = "";
      img.onload = () => {
        img.width = img.naturalWidth;
        img.height = img.naturalHeight;

        const datasetBytesBuffer = new ArrayBuffer(
          NUM_DATASET_ELEMENTS * IMAGE_SIZE * 4,
        );

        const chunkSize = 5000;
        canvas.width = img.width;
        canvas.height = chunkSize;

        for (let i = 0; i < NUM_DATASET_ELEMENTS / chunkSize; i++) {
          const datasetBytesView = new Float32Array(
            datasetBytesBuffer,
            i * IMAGE_SIZE * chunkSize * 4,
            IMAGE_SIZE * chunkSize,
          );
          ctx.drawImage(
            img,
            0,
            i * chunkSize,
            img.width,
            chunkSize,
            0,
            0,
            img.width,
            chunkSize,
          );

          const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

          for (let j = 0; j < imageData.data.length / 4; j++) {
            datasetBytesView[j] = imageData.data[j * 4] / 255;
          }
        }
        this.datasetImages = new Float32Array(datasetBytesBuffer);

        resolve();
      };
      img.onerror = reject;
      img.src = MNIST_IMAGES_SPRITE_PATH;
    });

    const labelsRequest = fetch(MNIST_LABELS_PATH);
    const [imgResponse, labelsResponse] = await Promise.all([
      imgRequest,
      labelsRequest,
    ]);

    this.datasetLabels = new Uint8Array(await labelsResponse.arrayBuffer());

    this.trainIndices = tf.util.createShuffledIndices(NUM_TRAIN_ELEMENTS);
    this.testIndices = tf.util.createShuffledIndices(NUM_TEST_ELEMENTS);

    this.trainImages = this.datasetImages.slice(
      0,
      IMAGE_SIZE * NUM_TRAIN_ELEMENTS,
    );
    this.testImages = this.datasetImages.slice(IMAGE_SIZE * NUM_TRAIN_ELEMENTS);
    this.trainLabels = this.datasetLabels.slice(
      0,
      NUM_CLASSES * NUM_TRAIN_ELEMENTS,
    );
    this.testLabels = this.datasetLabels.slice(
      NUM_CLASSES * NUM_TRAIN_ELEMENTS,
    );
  }

  nextTrainBatch(batchSize) {
    return this.nextBatch(
      batchSize,
      [this.trainImages, this.trainLabels],
      () => {
        this.shuffledTrainIndex =
          (this.shuffledTrainIndex + 1) % this.trainIndices.length;
        return this.trainIndices[this.shuffledTrainIndex];
      },
    );
  }

  nextTestBatch(batchSize) {
    return this.nextBatch(batchSize, [this.testImages, this.testLabels], () => {
      this.shuffledTestIndex =
        (this.shuffledTestIndex + 1) % this.testIndices.length;
      return this.testIndices[this.shuffledTestIndex];
    });
  }

  nextBatch(batchSize, data, index) {
    const batchImagesArray = new Float32Array(batchSize * IMAGE_SIZE);
    const batchLabelsArray = new Uint8Array(batchSize * NUM_CLASSES);

    for (let i = 0; i < batchSize; i++) {
      const idx = index();

      const image = data[0].slice(
        idx * IMAGE_SIZE,
        idx * IMAGE_SIZE + IMAGE_SIZE,
      );
      batchImagesArray.set(image, i * IMAGE_SIZE);

      const label = data[1].slice(
        idx * NUM_CLASSES,
        idx * NUM_CLASSES + NUM_CLASSES,
      );
      batchLabelsArray.set(label, i * NUM_CLASSES);
    }

    const xs = tf.tensor2d(batchImagesArray, [batchSize, IMAGE_SIZE]);
    const labels = tf.tensor2d(batchLabelsArray, [batchSize, NUM_CLASSES]);

    return { xs: xs.reshape([batchSize, 28, 28, 1]), labels };
  }
}

const IMAGE_SIZE = 784;
const NUM_CLASSES = 10;
const NUM_DATASET_ELEMENTS = 65000;
const NUM_TRAIN_ELEMENTS = 55000;
const NUM_TEST_ELEMENTS = NUM_DATASET_ELEMENTS - NUM_TRAIN_ELEMENTS;

// Load MNIST data
async function loadMNISTData() {
  const data = new MnistData();
  await data.load();
  return data;
}

// Train model
async function trainModel() {
  console.log("=".repeat(60));
  console.log("üöÄ STARTING MODEL TRAINING");
  console.log("=".repeat(60));

  document.getElementById("status").textContent = "Loading MNIST dataset...";
  document.getElementById("trainBtn").disabled = true;
  document.getElementById("progressContainer").style.display = "block";

  try {
    console.log("üì• Loading MNIST dataset...");
    const data = await loadMNISTData();
    window.mnistData = data; // Store for evaluation
    console.log("‚úÖ Dataset loaded successfully");
    console.log(`üìä Training samples: ${NUM_TRAIN_ELEMENTS}`);
    console.log(`üìä Test samples: ${NUM_TEST_ELEMENTS}`);

    document.getElementById("status").textContent = "Building CNN model...";
    console.log("\nüèóÔ∏è Building CNN model...");
    model = createModel();
    console.log("‚úÖ Model architecture created");
    model.summary();

    model.compile({
      optimizer: tf.train.adam(0.001),
      loss: "categoricalCrossentropy",
      metrics: ["accuracy"],
    });
    console.log("‚úÖ Model compiled with Adam optimizer (lr=0.001)");

    document.getElementById("status").textContent = "Training model...";

    const batchSize = 512;
    const epochs = 5;
    const trainBatchesPerEpoch = Math.floor(NUM_TRAIN_ELEMENTS / batchSize);

    console.log("\n" + "=".repeat(60));
    console.log("üéì TRAINING CONFIGURATION");
    console.log("=".repeat(60));
    console.log(`Batch size: ${batchSize}`);
    console.log(`Epochs: ${epochs}`);
    console.log(`Batches per epoch: ${trainBatchesPerEpoch}`);
    console.log(`Total batches: ${epochs * trainBatchesPerEpoch}`);
    console.log("=".repeat(60) + "\n");

    for (let epoch = 0; epoch < epochs; epoch++) {
      console.log(`\nüìö Epoch ${epoch + 1}/${epochs}`);
      console.log("-".repeat(60));

      let epochLoss = 0;
      let epochAcc = 0;

      for (let batch = 0; batch < trainBatchesPerEpoch; batch++) {
        const trainBatch = data.nextTrainBatch(batchSize);

        const history = await model.fit(trainBatch.xs, trainBatch.labels, {
          batchSize: batchSize,
          epochs: 1,
          verbose: 0,
        });

        epochLoss += history.history.loss[0];
        epochAcc += history.history.acc[0];

        trainBatch.xs.dispose();
        trainBatch.labels.dispose();

        // Update progress
        const totalBatches = epochs * trainBatchesPerEpoch;
        const currentBatch = epoch * trainBatchesPerEpoch + batch + 1;
        const progress = (currentBatch / totalBatches) * 100;

        document.getElementById("progressFill").style.width = progress + "%";
        document.getElementById("progressFill").textContent =
          Math.round(progress) + "%";

        // Log every 10 batches
        if ((batch + 1) % 10 === 0) {
          console.log(
            `  Batch ${batch + 1}/${trainBatchesPerEpoch} - Progress: ${progress.toFixed(1)}%`,
          );
        }
      }

      const avgLoss = epochLoss / trainBatchesPerEpoch;
      const avgAcc = epochAcc / trainBatchesPerEpoch;

      console.log("-".repeat(60));
      console.log(`‚úÖ Epoch ${epoch + 1} Complete:`);
      console.log(`   Loss: ${avgLoss.toFixed(4)}`);
      console.log(`   Accuracy: ${(avgAcc * 100).toFixed(2)}%`);

      document.getElementById("progressText").textContent =
        `Epoch ${epoch + 1}/${epochs} - Loss: ${avgLoss.toFixed(4)} - Accuracy: ${(avgAcc * 100).toFixed(2)}%`;

      document.getElementById("trainAccuracy").textContent =
        (avgAcc * 100).toFixed(2) + "%";
      document.getElementById("trainLoss").textContent = avgLoss.toFixed(4);
      document.getElementById("metricsContainer").style.display = "grid";

      await tf.nextFrame();
    }

    console.log("\n" + "=".repeat(60));
    console.log("üéâ TRAINING COMPLETE!");
    console.log("=".repeat(60));
    console.log("‚úÖ Model is ready for predictions");
    console.log("‚úÖ You can now draw digits or evaluate on test set");
    console.log("=".repeat(60) + "\n");

    document.getElementById("status").textContent =
      "‚úÖ Model trained successfully! Draw a digit or evaluate on test set.";
    document.getElementById("evaluateBtn").disabled = false;
    document.getElementById("predictBtn").disabled = false;
    document.getElementById("progressContainer").style.display = "none";
  } catch (error) {
    console.error("‚ùå TRAINING ERROR:", error);
    console.error("Error stack:", error.stack);
    document.getElementById("status").textContent =
      "‚ùå Error: " + error.message;
    document.getElementById("trainBtn").disabled = false;
    document.getElementById("progressContainer").style.display = "none";
  }
}

// Evaluate model
async function evaluateModel() {
  console.log("\n" + "=".repeat(60));
  console.log("üìä STARTING MODEL EVALUATION");
  console.log("=".repeat(60));

  document.getElementById("status").textContent =
    "Evaluating model on test set...";
  document.getElementById("evaluateBtn").disabled = true;

  try {
    const data = window.mnistData;
    const testBatchSize = 1000;
    const numTestBatches = Math.floor(NUM_TEST_ELEMENTS / testBatchSize);

    console.log("üìã Evaluation Configuration:");
    console.log(`   Test batch size: ${testBatchSize}`);
    console.log(`   Number of batches: ${numTestBatches}`);
    console.log(`   Total test samples: ${numTestBatches * testBatchSize}`);
    console.log("-".repeat(60));

    let totalCorrect = 0;
    let totalLoss = 0;

    for (let i = 0; i < numTestBatches; i++) {
      const testBatch = data.nextTestBatch(testBatchSize);

      const result = await model.evaluate(testBatch.xs, testBatch.labels, {
        batchSize: testBatchSize,
      });

      const predictions = model.predict(testBatch.xs);
      const predictedClasses = predictions.argMax(-1);
      const trueClasses = testBatch.labels.argMax(-1);

      const correct = await predictedClasses.equal(trueClasses).sum().data();
      totalCorrect += correct[0];

      const batchLoss = await result[0].data();
      totalLoss += batchLoss[0];

      console.log(
        `‚úì Batch ${i + 1}/${numTestBatches} - Correct: ${correct[0]}/${testBatchSize} (${((correct[0] / testBatchSize) * 100).toFixed(2)}%)`,
      );

      testBatch.xs.dispose();
      testBatch.labels.dispose();
      predictions.dispose();
      predictedClasses.dispose();
      trueClasses.dispose();
      result[0].dispose();
      result[1].dispose();
    }

    const testAcc = totalCorrect / (numTestBatches * testBatchSize);
    const avgTestLoss = totalLoss / numTestBatches;

    console.log("=".repeat(60));
    console.log("üìà EVALUATION RESULTS");
    console.log("=".repeat(60));
    console.log(`‚úÖ Test Accuracy: ${(testAcc * 100).toFixed(2)}%`);
    console.log(`üìâ Test Loss: ${avgTestLoss.toFixed(4)}`);
    console.log(
      `‚úì Correct Predictions: ${totalCorrect}/${numTestBatches * testBatchSize}`,
    );
    console.log(
      `‚úó Incorrect Predictions: ${numTestBatches * testBatchSize - totalCorrect}`,
    );
    console.log("=".repeat(60) + "\n");

    document.getElementById("testAccuracy").textContent =
      (testAcc * 100).toFixed(2) + "%";
    document.getElementById("status").textContent =
      `‚úÖ Test Accuracy: ${(testAcc * 100).toFixed(2)}% - Test Loss: ${avgTestLoss.toFixed(4)}`;

    // Show sample predictions
    console.log("üß™ Generating test samples visualization...\n");
    await showTestSamples();

    document.getElementById("evaluateBtn").disabled = false;
  } catch (error) {
    console.error("‚ùå EVALUATION ERROR:", error);
    console.error("Error stack:", error.stack);
    document.getElementById("status").textContent =
      "‚ùå Error evaluating: " + error.message;
    document.getElementById("evaluateBtn").disabled = false;
  }
}

// Show test samples
async function showTestSamples() {
  const numSamples = 20;
  const data = window.mnistData;

  console.log(`üé® Displaying ${numSamples} random test samples...`);

  const testSection = document.getElementById("testSection");
  const testResults = document.getElementById("testResults");
  testResults.innerHTML = "";
  testSection.style.display = "block";

  let correctCount = 0;

  for (let i = 0; i < numSamples; i++) {
    const testBatch = data.nextTestBatch(1);

    const prediction = model.predict(testBatch.xs);
    const predClass = (await prediction.argMax(-1).data())[0];
    const trueClass = (await testBatch.labels.argMax(-1).data())[0];

    const isCorrect = predClass === trueClass;
    if (isCorrect) correctCount++;

    console.log(
      `Sample ${i + 1}: True=${trueClass}, Predicted=${predClass} ${isCorrect ? "‚úì" : "‚úó"}`,
    );

    const sampleDiv = document.createElement("div");
    sampleDiv.className = "test-sample";

    const sampleCanvas = document.createElement("canvas");
    sampleCanvas.width = 28;
    sampleCanvas.height = 28;
    const sampleCtx = sampleCanvas.getContext("2d");

    const imageData = await testBatch.xs.reshape([28, 28]).data();
    const imgData = sampleCtx.createImageData(28, 28);
    for (let j = 0; j < 28 * 28; j++) {
      const val = imageData[j] * 255;
      imgData.data[j * 4] = val;
      imgData.data[j * 4 + 1] = val;
      imgData.data[j * 4 + 2] = val;
      imgData.data[j * 4 + 3] = 255;
    }
    sampleCtx.putImageData(imgData, 0, 0);

    const labelDiv = document.createElement("div");
    labelDiv.className =
      "test-label " + (predClass === trueClass ? "correct" : "incorrect");
    labelDiv.textContent = `${predClass === trueClass ? "‚úì" : "‚úó"} Pred: ${predClass} (${trueClass})`;

    sampleDiv.appendChild(sampleCanvas);
    sampleDiv.appendChild(labelDiv);
    testResults.appendChild(sampleDiv);

    testBatch.xs.dispose();
    testBatch.labels.dispose();
    prediction.dispose();
  }

  console.log(
    `\nüìä Sample Results: ${correctCount}/${numSamples} correct (${((correctCount / numSamples) * 100).toFixed(1)}%)\n`,
  );
}

// Predict digit from drawn canvas
async function predictDigit() {
  try {
    console.log("=".repeat(60));
    console.log("üîÆ STARTING PREDICTION");
    console.log("=".repeat(60));

    // Get image data from canvas
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    console.log("üìä Canvas Image Data:", {
      width: canvas.width,
      height: canvas.height,
      dataLength: imageData.data.length,
    });

    // Convert to grayscale and resize to 28x28
    const tensor = tf.tidy(() => {
      // Convert to tensor
      let img = tf.browser.fromPixels(imageData, 1);
      console.log("üìê Initial tensor shape:", img.shape);

      // Resize to 28x28
      img = tf.image.resizeBilinear(img, [28, 28]);
      console.log("üìê Resized tensor shape:", img.shape);

      // Normalize and invert (MNIST has white digits on black background)
      img = tf.scalar(1.0).sub(img.div(255.0));
      console.log("üìê Normalized tensor shape:", img.shape);

      // Reshape for model input
      const reshaped = img.reshape([1, 28, 28, 1]);
      console.log("üìê Final tensor shape:", reshaped.shape);
      return reshaped;
    });

    // Make prediction
    console.log("üß† Running model prediction...");
    const prediction = model.predict(tensor);
    const probabilities = await prediction.data();
    const predictedClass = await prediction.argMax(-1).data();

    console.log("\n" + "=".repeat(60));
    console.log("‚ú® PREDICTION RESULTS");
    console.log("=".repeat(60));
    console.log(`üéØ Predicted Digit: ${predictedClass[0]}`);
    console.log(
      `üíØ Confidence: ${(probabilities[predictedClass[0]] * 100).toFixed(2)}%`,
    );
    console.log("\nüìä All Class Probabilities:");
    console.log("-".repeat(60));

    // Create a sorted array of predictions for better visualization
    const predictions = [];
    for (let i = 0; i < 10; i++) {
      predictions.push({
        digit: i,
        probability: probabilities[i],
        percentage: (probabilities[i] * 100).toFixed(2),
      });
    }

    // Sort by probability (highest first)
    predictions.sort((a, b) => b.probability - a.probability);

    // Display in console as a table
    console.table(predictions);

    // Also display as a formatted list
    console.log("\nüìã Detailed Breakdown (sorted by confidence):");
    predictions.forEach((pred, index) => {
      const bar = "‚ñà".repeat(Math.round(pred.probability * 50));
      const emoji =
        index === 0 ? "ü•á" : index === 1 ? "ü•à" : index === 2 ? "ü•â" : "  ";
      console.log(`${emoji} Digit ${pred.digit}: ${pred.percentage}% ${bar}`);
    });

    console.log("\n" + "=".repeat(60));
    console.log("üìà Raw Probability Array:");
    console.log(
      Array.from(probabilities)
        .map((p, i) => `${i}: ${p.toFixed(6)}`)
        .join(", "),
    );
    console.log("=".repeat(60) + "\n");

    // Display results on UI
    document.getElementById("predictionResult").style.display = "block";
    document.getElementById("predictedDigit").textContent = predictedClass[0];
    document.getElementById("predictionConfidence").textContent =
      `Confidence: ${(probabilities[predictedClass[0]] * 100).toFixed(2)}%`;

    // Display all probabilities
    const predictionsGrid = document.getElementById("predictionsGrid");
    predictionsGrid.innerHTML = "";

    for (let i = 0; i < 10; i++) {
      const barDiv = document.createElement("div");
      barDiv.className = "prediction-bar";
      barDiv.innerHTML = `
                        <div class="prediction-bar-label">${i}</div>
                        <div class="prediction-bar-fill" style="width: ${probabilities[i] * 100}%"></div>
                        <div class="prediction-bar-value">${(probabilities[i] * 100).toFixed(1)}%</div>
                    `;
      predictionsGrid.appendChild(barDiv);
    }

    // Cleanup
    tensor.dispose();
    prediction.dispose();
  } catch (error) {
    console.error("‚ùå PREDICTION ERROR:", error);
    console.error("Error stack:", error.stack);
    alert("Error making prediction: " + error.message);
  }
}

// Initialize on page load
window.onload = () => {
  initCanvas();
  console.log("TensorFlow.js version:", tf.version.tfjs);
};
